{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T01:46:37.582666Z",
     "start_time": "2023-06-07T01:46:37.220978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay , classification_report , accuracy_score ,precision_recall_curve , roc_curve ,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T04:04:46.858442Z",
     "start_time": "2023-06-07T04:04:46.852359Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "vars = df.iloc[:, 2:-1]\n",
    "# vectorize the target data. M = 1 and B = 0 diagnosis\n",
    "target = df.iloc[:, 1].apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T04:04:48.670117Z",
     "start_time": "2023-06-07T04:04:48.138595Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['diagnosis'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mvars\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdiagnosis\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m y \u001B[38;5;241m=\u001B[39m target\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Use ANOVA F-value as the scoring function for feature selection \u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# f_classif is specify we using ANOVA\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# k is the number of features we want to get\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:5399\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5251\u001B[0m \u001B[38;5;129m@deprecate_nonkeyword_arguments\u001B[39m(version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, allowed_args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   5252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m   5253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5260\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5261\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5262\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5263\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5264\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5397\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5398\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5401\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5405\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5406\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5407\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4503\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4504\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4505\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4508\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4544\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4545\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4546\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4547\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4549\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4550\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6932\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   6933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 6934\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(labels[mask])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6935\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   6936\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['diagnosis'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X = vars.drop(['diagnosis'], axis=1)\n",
    "y = target\n",
    "# Use ANOVA F-value as the scoring function for feature selection \n",
    "# f_classif is specify we using ANOVA\n",
    "# k is the number of features we want to get\n",
    "selector = SelectKBest(score_func=f_classif, k=15)\n",
    "# Fit the selector to the data\n",
    "selector.fit(vars, target)\n",
    "# Get the scores and p-values of each feature\n",
    "scores = selector.scores_\n",
    "p_values = selector.pvalues_\n",
    "\n",
    "results = pd.DataFrame({'Feature': vars.columns, 'Score': scores, 'p-value': p_values})\n",
    "results.sort_values(by='Score', ascending=False, inplace=True)\n",
    "# Select the top K features based on the scores\n",
    "top_features = vars.columns[selector.get_support()]\n",
    "# Display the top features\n",
    "print(top_features)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T04:01:53.392080Z",
     "start_time": "2023-06-07T04:01:53.368688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     radius_mean  perimeter_mean  area_mean  compactness_mean  concavity_mean  \\\n0          17.99          122.80     1001.0           0.27760         0.30010   \n1          20.57          132.90     1326.0           0.07864         0.08690   \n2          19.69          130.00     1203.0           0.15990         0.19740   \n3          11.42           77.58      386.1           0.28390         0.24140   \n4          20.29          135.10     1297.0           0.13280         0.19800   \n..           ...             ...        ...               ...             ...   \n564        21.56          142.00     1479.0           0.11590         0.24390   \n565        20.13          131.20     1261.0           0.10340         0.14400   \n566        16.60          108.30      858.1           0.10230         0.09251   \n567        20.60          140.10     1265.0           0.27700         0.35140   \n568         7.76           47.92      181.0           0.04362         0.00000   \n\n     concave points_mean  radius_se  perimeter_se  area_se  radius_worst  \\\n0                0.14710     1.0950         8.589   153.40        25.380   \n1                0.07017     0.5435         3.398    74.08        24.990   \n2                0.12790     0.7456         4.585    94.03        23.570   \n3                0.10520     0.4956         3.445    27.23        14.910   \n4                0.10430     0.7572         5.438    94.44        22.540   \n..                   ...        ...           ...      ...           ...   \n564              0.13890     1.1760         7.673   158.70        25.450   \n565              0.09791     0.7655         5.203    99.04        23.690   \n566              0.05302     0.4564         3.425    48.55        18.980   \n567              0.15200     0.7260         5.772    86.22        25.740   \n568              0.00000     0.3857         2.548    19.15         9.456   \n\n     perimeter_worst  area_worst  compactness_worst  concavity_worst  \\\n0             184.60      2019.0            0.66560           0.7119   \n1             158.80      1956.0            0.18660           0.2416   \n2             152.50      1709.0            0.42450           0.4504   \n3              98.87       567.7            0.86630           0.6869   \n4             152.20      1575.0            0.20500           0.4000   \n..               ...         ...                ...              ...   \n564           166.10      2027.0            0.21130           0.4107   \n565           155.00      1731.0            0.19220           0.3215   \n566           126.70      1124.0            0.30940           0.3403   \n567           184.60      1821.0            0.86810           0.9387   \n568            59.16       268.6            0.06444           0.0000   \n\n     concave points_worst  \n0                  0.2654  \n1                  0.1860  \n2                  0.2430  \n3                  0.2575  \n4                  0.1625  \n..                    ...  \n564                0.2216  \n565                0.1628  \n566                0.1418  \n567                0.2650  \n568                0.0000  \n\n[569 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>radius_se</th>\n      <th>perimeter_se</th>\n      <th>area_se</th>\n      <th>radius_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>1.0950</td>\n      <td>8.589</td>\n      <td>153.40</td>\n      <td>25.380</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.5435</td>\n      <td>3.398</td>\n      <td>74.08</td>\n      <td>24.990</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.7456</td>\n      <td>4.585</td>\n      <td>94.03</td>\n      <td>23.570</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.4956</td>\n      <td>3.445</td>\n      <td>27.23</td>\n      <td>14.910</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.7572</td>\n      <td>5.438</td>\n      <td>94.44</td>\n      <td>22.540</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>1.1760</td>\n      <td>7.673</td>\n      <td>158.70</td>\n      <td>25.450</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.7655</td>\n      <td>5.203</td>\n      <td>99.04</td>\n      <td>23.690</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.4564</td>\n      <td>3.425</td>\n      <td>48.55</td>\n      <td>18.980</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.7260</td>\n      <td>5.772</td>\n      <td>86.22</td>\n      <td>25.740</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.3857</td>\n      <td>2.548</td>\n      <td>19.15</td>\n      <td>9.456</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.loc[:,top_features]\n",
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T04:01:55.535018Z",
     "start_time": "2023-06-07T04:01:55.531378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stratify: split the training and testing by 80/20\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(vars, target, train_size=0.8,test_size=0.2,stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T04:01:57.414348Z",
     "start_time": "2023-06-07T04:01:57.399343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     radius_mean  perimeter_mean  area_mean  compactness_mean  concavity_mean  \\\n177       16.460          109.30      832.9           0.15560         0.17930   \n169       14.970           96.22      685.9           0.07885         0.02602   \n4         20.290          135.10     1297.0           0.13280         0.19800   \n504        9.268           61.49      248.7           0.22390         0.09730   \n90        14.620           94.57      662.7           0.08606         0.03102   \n..           ...             ...        ...               ...             ...   \n386       12.210           78.78      462.0           0.07823         0.06839   \n490       12.250           78.18      466.5           0.05200         0.01714   \n391        8.734           55.27      234.3           0.07428         0.00000   \n482       13.470           87.32      546.3           0.11550         0.05786   \n319       12.430           78.60      477.3           0.03454         0.01342   \n\n     concave points_mean  radius_se  perimeter_se  area_se  radius_worst  \\\n177              0.08866     0.3037         2.482    31.59         17.79   \n169              0.03781     0.2713         1.893    24.28         16.11   \n4                0.10430     0.7572         5.438    94.44         22.54   \n504              0.05252     0.4076         3.014    20.04         10.28   \n90               0.02957     0.3721         2.279    33.76         16.11   \n..                   ...        ...           ...      ...           ...   \n386              0.02534     0.2666         2.097    19.96         13.13   \n490              0.01261     0.2239         1.577    18.04         14.17   \n391              0.00000     0.5169         3.167    28.85         10.17   \n482              0.05266     0.1588         1.102    12.84         14.83   \n319              0.01699     0.3778         2.487    31.16         12.90   \n\n     perimeter_worst  area_worst  compactness_worst  concavity_worst  \\\n177           123.50       981.2            0.46670          0.58620   \n169           104.60       793.7            0.16370          0.06648   \n4             152.20      1575.0            0.20500          0.40000   \n504            69.05       300.2            0.34410          0.20990   \n90            102.90       803.7            0.17660          0.09189   \n..               ...         ...                ...              ...   \n386            87.65       529.9            0.24310          0.30760   \n490            92.74       622.9            0.18040          0.12300   \n391            64.01       317.0            0.13100          0.00000   \n482            94.94       660.2            0.24990          0.18480   \n319            81.76       515.9            0.04712          0.02237   \n\n     concave points_worst  \n177               0.20350  \n169               0.08485  \n4                 0.16250  \n504               0.10250  \n90                0.06946  \n..                    ...  \n386               0.09140  \n490               0.06335  \n391               0.00000  \n482               0.13350  \n319               0.02832  \n\n[455 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>radius_se</th>\n      <th>perimeter_se</th>\n      <th>area_se</th>\n      <th>radius_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>177</th>\n      <td>16.460</td>\n      <td>109.30</td>\n      <td>832.9</td>\n      <td>0.15560</td>\n      <td>0.17930</td>\n      <td>0.08866</td>\n      <td>0.3037</td>\n      <td>2.482</td>\n      <td>31.59</td>\n      <td>17.79</td>\n      <td>123.50</td>\n      <td>981.2</td>\n      <td>0.46670</td>\n      <td>0.58620</td>\n      <td>0.20350</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>14.970</td>\n      <td>96.22</td>\n      <td>685.9</td>\n      <td>0.07885</td>\n      <td>0.02602</td>\n      <td>0.03781</td>\n      <td>0.2713</td>\n      <td>1.893</td>\n      <td>24.28</td>\n      <td>16.11</td>\n      <td>104.60</td>\n      <td>793.7</td>\n      <td>0.16370</td>\n      <td>0.06648</td>\n      <td>0.08485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.290</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.7572</td>\n      <td>5.438</td>\n      <td>94.44</td>\n      <td>22.54</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.20500</td>\n      <td>0.40000</td>\n      <td>0.16250</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>9.268</td>\n      <td>61.49</td>\n      <td>248.7</td>\n      <td>0.22390</td>\n      <td>0.09730</td>\n      <td>0.05252</td>\n      <td>0.4076</td>\n      <td>3.014</td>\n      <td>20.04</td>\n      <td>10.28</td>\n      <td>69.05</td>\n      <td>300.2</td>\n      <td>0.34410</td>\n      <td>0.20990</td>\n      <td>0.10250</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>14.620</td>\n      <td>94.57</td>\n      <td>662.7</td>\n      <td>0.08606</td>\n      <td>0.03102</td>\n      <td>0.02957</td>\n      <td>0.3721</td>\n      <td>2.279</td>\n      <td>33.76</td>\n      <td>16.11</td>\n      <td>102.90</td>\n      <td>803.7</td>\n      <td>0.17660</td>\n      <td>0.09189</td>\n      <td>0.06946</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>12.210</td>\n      <td>78.78</td>\n      <td>462.0</td>\n      <td>0.07823</td>\n      <td>0.06839</td>\n      <td>0.02534</td>\n      <td>0.2666</td>\n      <td>2.097</td>\n      <td>19.96</td>\n      <td>13.13</td>\n      <td>87.65</td>\n      <td>529.9</td>\n      <td>0.24310</td>\n      <td>0.30760</td>\n      <td>0.09140</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>12.250</td>\n      <td>78.18</td>\n      <td>466.5</td>\n      <td>0.05200</td>\n      <td>0.01714</td>\n      <td>0.01261</td>\n      <td>0.2239</td>\n      <td>1.577</td>\n      <td>18.04</td>\n      <td>14.17</td>\n      <td>92.74</td>\n      <td>622.9</td>\n      <td>0.18040</td>\n      <td>0.12300</td>\n      <td>0.06335</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>8.734</td>\n      <td>55.27</td>\n      <td>234.3</td>\n      <td>0.07428</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.5169</td>\n      <td>3.167</td>\n      <td>28.85</td>\n      <td>10.17</td>\n      <td>64.01</td>\n      <td>317.0</td>\n      <td>0.13100</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>13.470</td>\n      <td>87.32</td>\n      <td>546.3</td>\n      <td>0.11550</td>\n      <td>0.05786</td>\n      <td>0.05266</td>\n      <td>0.1588</td>\n      <td>1.102</td>\n      <td>12.84</td>\n      <td>14.83</td>\n      <td>94.94</td>\n      <td>660.2</td>\n      <td>0.24990</td>\n      <td>0.18480</td>\n      <td>0.13350</td>\n    </tr>\n    <tr>\n      <th>319</th>\n      <td>12.430</td>\n      <td>78.60</td>\n      <td>477.3</td>\n      <td>0.03454</td>\n      <td>0.01342</td>\n      <td>0.01699</td>\n      <td>0.3778</td>\n      <td>2.487</td>\n      <td>31.16</td>\n      <td>12.90</td>\n      <td>81.76</td>\n      <td>515.9</td>\n      <td>0.04712</td>\n      <td>0.02237</td>\n      <td>0.02832</td>\n    </tr>\n  </tbody>\n</table>\n<p>455 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     radius_mean  perimeter_mean  area_mean  compactness_mean  concavity_mean  \\\n2          19.69          130.00     1203.0           0.15990         0.19740   \n456        11.63           74.87      415.1           0.08574         0.07160   \n433        18.82          123.70     1110.0           0.13890         0.15940   \n143        12.90           83.74      512.2           0.09509         0.04894   \n95         20.26          132.40     1264.0           0.13130         0.14650   \n..           ...             ...        ...               ...             ...   \n189        12.30           78.83      463.7           0.07253         0.03844   \n494        13.16           84.06      538.7           0.05275         0.01800   \n442        13.78           88.37      585.9           0.06718         0.01055   \n449        21.10          138.10     1384.0           0.11750         0.15720   \n278        13.59           86.24      572.3           0.04052         0.01997   \n\n     concave points_mean  radius_se  perimeter_se  area_se  radius_worst  \\\n2               0.127900     0.7456         4.585    94.03         23.57   \n456             0.020170     0.3135         2.150    23.13         13.12   \n433             0.087440     0.8191         4.493   103.90         22.66   \n143             0.030880     0.2143         1.689    16.64         14.48   \n95              0.086830     0.7576         4.554    87.87         24.22   \n..                   ...        ...           ...      ...           ...   \n189             0.016540     0.2382         1.687    18.32         13.35   \n494             0.012560     0.3237         2.326    26.07         14.50   \n442             0.009937     0.3563         2.235    29.34         15.27   \n449             0.115500     0.6643         4.542    81.89         25.68   \n278             0.012380     0.2580         1.683    22.22         15.50   \n\n     perimeter_worst  area_worst  compactness_worst  concavity_worst  \\\n2             152.50      1709.0            0.42450          0.45040   \n456            86.04       527.8            0.20310          0.29230   \n433           145.30      1603.0            0.34630          0.39120   \n143            97.17       643.8            0.25480          0.20900   \n95            156.10      1750.0            0.35390          0.40980   \n..               ...         ...                ...              ...   \n189            86.65       546.7            0.16500          0.14230   \n494            95.29       648.3            0.16460          0.07698   \n442            97.90       706.6            0.10710          0.03517   \n449           168.20      2022.0            0.31010          0.43990   \n278            98.91       739.1            0.07622          0.10600   \n\n     concave points_worst  \n2                 0.24300  \n456               0.06835  \n433               0.17080  \n143               0.10120  \n95                0.15730  \n..                    ...  \n189               0.04815  \n494               0.04195  \n442               0.03312  \n449               0.22800  \n278               0.05185  \n\n[114 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>radius_se</th>\n      <th>perimeter_se</th>\n      <th>area_se</th>\n      <th>radius_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.127900</td>\n      <td>0.7456</td>\n      <td>4.585</td>\n      <td>94.03</td>\n      <td>23.57</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.42450</td>\n      <td>0.45040</td>\n      <td>0.24300</td>\n    </tr>\n    <tr>\n      <th>456</th>\n      <td>11.63</td>\n      <td>74.87</td>\n      <td>415.1</td>\n      <td>0.08574</td>\n      <td>0.07160</td>\n      <td>0.020170</td>\n      <td>0.3135</td>\n      <td>2.150</td>\n      <td>23.13</td>\n      <td>13.12</td>\n      <td>86.04</td>\n      <td>527.8</td>\n      <td>0.20310</td>\n      <td>0.29230</td>\n      <td>0.06835</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>18.82</td>\n      <td>123.70</td>\n      <td>1110.0</td>\n      <td>0.13890</td>\n      <td>0.15940</td>\n      <td>0.087440</td>\n      <td>0.8191</td>\n      <td>4.493</td>\n      <td>103.90</td>\n      <td>22.66</td>\n      <td>145.30</td>\n      <td>1603.0</td>\n      <td>0.34630</td>\n      <td>0.39120</td>\n      <td>0.17080</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>12.90</td>\n      <td>83.74</td>\n      <td>512.2</td>\n      <td>0.09509</td>\n      <td>0.04894</td>\n      <td>0.030880</td>\n      <td>0.2143</td>\n      <td>1.689</td>\n      <td>16.64</td>\n      <td>14.48</td>\n      <td>97.17</td>\n      <td>643.8</td>\n      <td>0.25480</td>\n      <td>0.20900</td>\n      <td>0.10120</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>20.26</td>\n      <td>132.40</td>\n      <td>1264.0</td>\n      <td>0.13130</td>\n      <td>0.14650</td>\n      <td>0.086830</td>\n      <td>0.7576</td>\n      <td>4.554</td>\n      <td>87.87</td>\n      <td>24.22</td>\n      <td>156.10</td>\n      <td>1750.0</td>\n      <td>0.35390</td>\n      <td>0.40980</td>\n      <td>0.15730</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>12.30</td>\n      <td>78.83</td>\n      <td>463.7</td>\n      <td>0.07253</td>\n      <td>0.03844</td>\n      <td>0.016540</td>\n      <td>0.2382</td>\n      <td>1.687</td>\n      <td>18.32</td>\n      <td>13.35</td>\n      <td>86.65</td>\n      <td>546.7</td>\n      <td>0.16500</td>\n      <td>0.14230</td>\n      <td>0.04815</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>13.16</td>\n      <td>84.06</td>\n      <td>538.7</td>\n      <td>0.05275</td>\n      <td>0.01800</td>\n      <td>0.012560</td>\n      <td>0.3237</td>\n      <td>2.326</td>\n      <td>26.07</td>\n      <td>14.50</td>\n      <td>95.29</td>\n      <td>648.3</td>\n      <td>0.16460</td>\n      <td>0.07698</td>\n      <td>0.04195</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>13.78</td>\n      <td>88.37</td>\n      <td>585.9</td>\n      <td>0.06718</td>\n      <td>0.01055</td>\n      <td>0.009937</td>\n      <td>0.3563</td>\n      <td>2.235</td>\n      <td>29.34</td>\n      <td>15.27</td>\n      <td>97.90</td>\n      <td>706.6</td>\n      <td>0.10710</td>\n      <td>0.03517</td>\n      <td>0.03312</td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>21.10</td>\n      <td>138.10</td>\n      <td>1384.0</td>\n      <td>0.11750</td>\n      <td>0.15720</td>\n      <td>0.115500</td>\n      <td>0.6643</td>\n      <td>4.542</td>\n      <td>81.89</td>\n      <td>25.68</td>\n      <td>168.20</td>\n      <td>2022.0</td>\n      <td>0.31010</td>\n      <td>0.43990</td>\n      <td>0.22800</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>13.59</td>\n      <td>86.24</td>\n      <td>572.3</td>\n      <td>0.04052</td>\n      <td>0.01997</td>\n      <td>0.012380</td>\n      <td>0.2580</td>\n      <td>1.683</td>\n      <td>22.22</td>\n      <td>15.50</td>\n      <td>98.91</td>\n      <td>739.1</td>\n      <td>0.07622</td>\n      <td>0.10600</td>\n      <td>0.05185</td>\n    </tr>\n  </tbody>\n</table>\n<p>114 rows × 15 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "177    1\n169    0\n4      1\n504    0\n90     0\n      ..\n386    0\n490    0\n391    0\n482    0\n319    0\nName: diagnosis, Length: 455, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "2      1\n456    0\n433    1\n143    0\n95     1\n      ..\n189    0\n494    0\n442    0\n449    1\n278    0\nName: diagnosis, Length: 114, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_features)\n",
    "display(test_features)\n",
    "display(train_targets)\n",
    "display(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "id                           0\nradius_mean                  0\ntexture_mean                 0\nperimeter_mean               0\narea_mean                    0\nsmoothness_mean              0\ncompactness_mean             0\nconcavity_mean               0\nconcave points_mean          0\nsymmetry_mean                0\nfractal_dimension_mean       0\nradius_se                    0\ntexture_se                   0\nperimeter_se                 0\narea_se                      0\nsmoothness_se                0\ncompactness_se               0\nconcavity_se                 0\nconcave points_se            0\nsymmetry_se                  0\nfractal_dimension_se         0\nradius_worst                 0\ntexture_worst                0\nperimeter_worst              0\narea_worst                   0\nsmoothness_worst             0\ncompactness_worst            0\nconcavity_worst              0\nconcave points_worst         0\nsymmetry_worst               0\nfractal_dimension_worst      0\nUnnamed: 32                567\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m clf \u001B[38;5;241m=\u001B[39m GridSearchCV(log_model, param_grid \u001B[38;5;241m=\u001B[39m hyperparameters, cv \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m display(np\u001B[38;5;241m.\u001B[39misnan(X)\u001B[38;5;241m.\u001B[39msum())\n\u001B[0;32m---> 11\u001B[0m \u001B[43mlog_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1194\u001B[0m     _dtype \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mfloat64, np\u001B[38;5;241m.\u001B[39mfloat32]\n\u001B[0;32m-> 1196\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1197\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1198\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1199\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1202\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mliblinear\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msag\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msaga\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1203\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1204\u001B[0m check_classification_targets(y)\n\u001B[1;32m   1205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:584\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    582\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1101\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1103\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1104\u001B[0m     )\n\u001B[0;32m-> 1106\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1109\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1122\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1124\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "hyperparameters = [\n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "     'C' : np.logspace(-4, 4, 20),\n",
    "     'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "     'max_iter' : [100, 1000, 2500, 5000]\n",
    "     }\n",
    "]\n",
    "log_model = LogisticRegression()\n",
    "clf = GridSearchCV(log_model, param_grid = hyperparameters, cv = 3, n_jobs=-1)\n",
    "display(np.isnan(X).sum())\n",
    "log_model.fit(X, y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T04:04:52.367939Z",
     "start_time": "2023-06-07T04:04:52.311687Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
